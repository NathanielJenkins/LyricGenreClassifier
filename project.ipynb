{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project\n",
    "# github restricts file size, dataset can be downloaded from https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n  return f(*args, **kwds)\n"
    }
   ],
   "source": [
    "# import the dataset\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('lyrics.csv')\n",
    "data.head()\n",
    "\n",
    "# temp so that it runs during testing\n",
    "data = data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(6212, 6)\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n  return f(*args, **kwds)\n"
    }
   ],
   "source": [
    "# preprocess the data\n",
    "\n",
    "# remove all the genres with not avaliable and other\n",
    "data = data[data.genre != 'Not Available']\n",
    "data = data[data.genre != 'Other']\n",
    "\n",
    "\n",
    "# remove all the data with no lyrics\n",
    "data.dropna(subset=['lyrics'], inplace=True)\n",
    "print(data.shape)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>10</th>\n      <th>2x</th>\n      <th>40</th>\n      <th>50</th>\n      <th>across</th>\n      <th>act</th>\n      <th>admit</th>\n      <th>afraid</th>\n      <th>age</th>\n      <th>ago</th>\n      <th>...</th>\n      <th>îµî</th>\n      <th>îµî¹ï</th>\n      <th>îµï</th>\n      <th>î¹</th>\n      <th>î¹î</th>\n      <th>îºî</th>\n      <th>î¼î</th>\n      <th>î¼îµ</th>\n      <th>î½</th>\n      <th>î½î</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6207</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6208</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6209</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6210</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6211</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6212 rows × 1500 columns</p>\n</div>",
      "text/plain": "      10  2x  40  50  across  act  admit  afraid  age  ago  ...  îµî  îµî¹ï  \\\n0      0   0   0   0       0    0      1       0    0    0  ...    0      0   \n1      0   0   0   0       0    0      0       0    0    0  ...    0      0   \n2      0   0   0   0       0    0      0       0    0    0  ...    0      0   \n3      0   0   0   0       0    0      0       0    0    0  ...    0      0   \n4      0   0   0   0       0    0      0       0    0    0  ...    0      0   \n...   ..  ..  ..  ..     ...  ...    ...     ...  ...  ...  ...  ...    ...   \n6207   0   0   0   0       0    0      0       0    0    0  ...    0      0   \n6208   0   0   0   0       0    0      0       0    0    0  ...    0      0   \n6209   0   0   0   0       0    0      0       0    0    0  ...    0      0   \n6210   0   0   0   0       0    0      0       0    0    0  ...    0      0   \n6211   0   0   0   0       0    0      0       0    0    0  ...    0      0   \n\n      îµï  î¹  î¹î  îºî  î¼î  î¼îµ  î½  î½î  \n0       0   0    0    0    0     0   0    0  \n1       0   0    0    0    0     0   0    0  \n2       0   0    0    0    0     0   0    0  \n3       0   0    0    0    0     0   0    0  \n4       0   0    0    0    0     0   0    0  \n...   ...  ..  ...  ...  ...   ...  ..  ...  \n6207    0   0    0    0    0     0   0    0  \n6208    0   0    0    0    0     0   0    0  \n6209    0   0    0    0    0     0   0    0  \n6210    0   0    0    0    0     0   0    0  \n6211    0   0    0    0    0     0   0    0  \n\n[6212 rows x 1500 columns]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# max_features : a maximum of 1500 columns\n",
    "# min_df : the word must occur in a mininum of 5 documents\n",
    "# max_df : the word occurs in less than 70 percent of the documents (words appearing in all are useless)\n",
    "# nltk.download('stopwords')\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=2, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "\n",
    "# creates a bag of words\n",
    "X = vectorizer.fit_transform(data.lyrics.values.astype('str'))\n",
    "\n",
    "# creates y, which is our genre class\n",
    "y = data.genre\n",
    "\n",
    "# visualize the transformed data \n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    ",# find the TFID reference: http://www.tfidf.com/\n",
    "# mitigates the fact that the word may have a high frequency in other documents\n",
    "\n",
    "# TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "# IDF(t) = log_e(Total number of documents / Number of documents with term t in it). <-- appro \n",
    "    # if all documents have the term in it then it has a score of 0 TF * log(1) = 0\n",
    "    # it will weigh rare words heigher \n",
    "\n",
    "# TFIDF = TF * IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>10</th>\n      <th>2x</th>\n      <th>40</th>\n      <th>50</th>\n      <th>across</th>\n      <th>act</th>\n      <th>admit</th>\n      <th>afraid</th>\n      <th>age</th>\n      <th>ago</th>\n      <th>...</th>\n      <th>îµî</th>\n      <th>îµî¹ï</th>\n      <th>îµï</th>\n      <th>î¹</th>\n      <th>î¹î</th>\n      <th>îºî</th>\n      <th>î¼î</th>\n      <th>î¼îµ</th>\n      <th>î½</th>\n      <th>î½î</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.067852</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6207</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6208</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6209</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6210</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6211</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6212 rows × 1500 columns</p>\n</div>",
      "text/plain": "       10   2x   40   50  across  act     admit  afraid  age  ago  ...  îµî  \\\n0     0.0  0.0  0.0  0.0     0.0  0.0  0.067852     0.0  0.0  0.0  ...  0.0   \n1     0.0  0.0  0.0  0.0     0.0  0.0  0.000000     0.0  0.0  0.0  ...  0.0   \n2     0.0  0.0  0.0  0.0     0.0  0.0  0.000000     0.0  0.0  0.0  ...  0.0   \n3     0.0  0.0  0.0  0.0     0.0  0.0  0.000000     0.0  0.0  0.0  ...  0.0   \n4     0.0  0.0  0.0  0.0     0.0  0.0  0.000000     0.0  0.0  0.0  ...  0.0   \n...   ...  ...  ...  ...     ...  ...       ...     ...  ...  ...  ...  ...   \n6207  0.0  0.0  0.0  0.0     0.0  0.0  0.000000     0.0  0.0  0.0  ...  0.0   \n6208  0.0  0.0  0.0  0.0     0.0  0.0  0.000000     0.0  0.0  0.0  ...  0.0   \n6209  0.0  0.0  0.0  0.0     0.0  0.0  0.000000     0.0  0.0  0.0  ...  0.0   \n6210  0.0  0.0  0.0  0.0     0.0  0.0  0.000000     0.0  0.0  0.0  ...  0.0   \n6211  0.0  0.0  0.0  0.0     0.0  0.0  0.000000     0.0  0.0  0.0  ...  0.0   \n\n      îµî¹ï  îµï   î¹  î¹î  îºî  î¼î  î¼îµ   î½  î½î  \n0       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n1       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n2       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n3       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n4       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n...     ...  ...  ...  ...  ...  ...   ...  ...  ...  \n6207    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n6208    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n6209    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n6210    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n6211    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n\n[6212 rows x 1500 columns]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice how the data is now altered based on the word frequency\n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training a test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_predict(classifiers):\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        print(classifier.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\nRandomForestClassifier 0.5872504829362524\n              precision    recall  f1-score   support\n\n     Country       0.25      0.02      0.04        45\n  Electronic       0.64      0.24      0.35        66\n        Folk       0.40      0.06      0.10        36\n     Hip-Hop       0.84      0.82      0.83       203\n       Indie       1.00      0.17      0.29        30\n        Jazz       0.43      0.11      0.17        83\n       Metal       0.54      0.47      0.50       175\n         Pop       0.42      0.25      0.31       222\n         R&B       0.00      0.00      0.00         4\n        Rock       0.57      0.83      0.68       689\n\n    accuracy                           0.59      1553\n   macro avg       0.51      0.30      0.33      1553\nweighted avg       0.57      0.59      0.54      1553\n\nMultinomialNB 0.583386992916935\n              precision    recall  f1-score   support\n\n     Country       0.00      0.00      0.00        45\n  Electronic       1.00      0.21      0.35        66\n        Folk       0.00      0.00      0.00        36\n     Hip-Hop       0.89      0.74      0.81       203\n       Indie       0.00      0.00      0.00        30\n        Jazz       0.00      0.00      0.00        83\n       Metal       0.75      0.42      0.54       175\n         Pop       0.53      0.11      0.18       222\n         R&B       0.00      0.00      0.00         4\n        Rock       0.52      0.93      0.67       689\n\n    accuracy                           0.58      1553\n   macro avg       0.37      0.24      0.26      1553\nweighted avg       0.55      0.58      0.51      1553\n\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\nLogisticRegression 0.6039922730199614\n              precision    recall  f1-score   support\n\n     Country       0.00      0.00      0.00        45\n  Electronic       1.00      0.18      0.31        66\n        Folk       1.00      0.03      0.05        36\n     Hip-Hop       0.92      0.77      0.84       203\n       Indie       0.00      0.00      0.00        30\n        Jazz       0.25      0.01      0.02        83\n       Metal       0.66      0.50      0.57       175\n         Pop       0.49      0.20      0.29       222\n         R&B       0.00      0.00      0.00         4\n        Rock       0.56      0.92      0.69       689\n\n    accuracy                           0.60      1553\n   macro avg       0.49      0.26      0.28      1553\nweighted avg       0.59      0.60      0.54      1553\n\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "classifers = [RandomForestClassifier(), MultinomialNB(), LogisticRegression()]\n",
    "train_predict(classifers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}