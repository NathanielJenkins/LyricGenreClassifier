{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project\n",
    "# github restricts file size, dataset can be downloaded from https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-ba8f74671894>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-ba8f74671894>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ** Anthing you like **\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<h1 align = \"center\">Genre Classification by Lyric Analysis</h1>\n",
    "<h2 align = \"center\">Dataming Project</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Introduction</h2>\n",
    "<p>\n",
    "Online streaming platforms like Apple Music and Spotify add new songs to their collection daily. Each platform gives users the ability to listen to and download millions unque of songs. These songs are catalogued and categorized so that music listeners may find new songs that match their unique tastes. \n",
    "\n",
    "Organizing songs by genre is an old and familiar technique to categorize music and make it easier for listeners to find songs they like. To classify songs into genres manually, someone would need to listen to it and select the genre that best applies. This is hard and very time-consuming job. They would require a knowledge of ,many different genres, types of music and the nuances between them. \n",
    "\n",
    "Machine learning and text lyric analysis can aid in this pursuit. \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "This report serves to identify if there is a link between word frequency within the lyrics of a song and genre that the song belongs to. By using different machine learning techniques and word frequency analysis ....\n",
    "\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>The Dataset</h2>\n",
    "<p>The dataset can be obtained</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "\n",
    "# remove all the genres with not avaliable and other\n",
    "data = data[data.genre != 'Not Available']\n",
    "data = data[data.genre != 'Other']\n",
    "\n",
    "\n",
    "# remove all the data with no lyrics\n",
    "data.dropna(subset=['lyrics'], inplace=True)\n",
    "print(data.shape)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('lyrics.csv')\n",
    "data.head()\n",
    "\n",
    "# temp so that it runs during testing\n",
    "data = data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# max_features : a maximum of 1500 columns\n",
    "# min_df : the word must occur in a mininum of 5 documents\n",
    "# max_df : the word occurs in less than 70 percent of the documents (words appearing in all are useless)\n",
    "# nltk.download('stopwords')\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=2, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "\n",
    "# creates a bag of words\n",
    "X = vectorizer.fit_transform(data.lyrics.values.astype('str'))\n",
    "\n",
    "# creates y, which is our genre class\n",
    "y = data.genre\n",
    "\n",
    "# visualize the transformed data \n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    ",# find the TFID reference: http://www.tfidf.com/\n",
    "# mitigates the fact that the word may have a high frequency in other documents\n",
    "\n",
    "# TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "# IDF(t) = log_e(Total number of documents / Number of documents with term t in it). <-- appro \n",
    "    # if all documents have the term in it then it has a score of 0 TF * log(1) = 0\n",
    "    # it will weigh rare words heigher \n",
    "\n",
    "# TFIDF = TF * IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice how the data is now altered based on the word frequency\n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training a test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_predict(classifiers):\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        print(classifier.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\nRandomForestClassifier 0.5692816163631829\n              precision    recall  f1-score   support\n\n     Country       0.49      0.19      0.28      1156\n  Electronic       0.55      0.09      0.15       535\n        Folk       0.77      0.18      0.29       204\n     Hip-Hop       0.81      0.74      0.77      1606\n       Indie       0.69      0.05      0.09       193\n        Jazz       0.61      0.21      0.31       563\n       Metal       0.58      0.34      0.43      1617\n         Pop       0.46      0.31      0.37      2807\n         R&B       0.75      0.10      0.17       187\n        Rock       0.56      0.85      0.67      7168\n\n    accuracy                           0.57     16036\n   macro avg       0.63      0.31      0.35     16036\nweighted avg       0.57      0.57      0.53     16036\n\nMultinomialNB 0.5277500623596907\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n              precision    recall  f1-score   support\n\n     Country       0.63      0.01      0.03      1156\n  Electronic       0.86      0.03      0.06       535\n        Folk       0.89      0.04      0.08       204\n     Hip-Hop       0.77      0.65      0.70      1606\n       Indie       0.00      0.00      0.00       193\n        Jazz       1.00      0.00      0.00       563\n       Metal       0.71      0.27      0.39      1617\n         Pop       0.37      0.11      0.18      2807\n         R&B       0.00      0.00      0.00       187\n        Rock       0.50      0.92      0.65      7168\n\n    accuracy                           0.53     16036\n   macro avg       0.57      0.20      0.21     16036\nweighted avg       0.56      0.53      0.44     16036\n\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\nLogisticRegression 0.5675355450236966\n              precision    recall  f1-score   support\n\n     Country       0.59      0.20      0.30      1156\n  Electronic       0.81      0.04      0.07       535\n        Folk       0.83      0.07      0.14       204\n     Hip-Hop       0.85      0.67      0.75      1606\n       Indie       0.00      0.00      0.00       193\n        Jazz       0.42      0.04      0.08       563\n       Metal       0.68      0.36      0.47      1617\n         Pop       0.47      0.24      0.32      2807\n         R&B       0.00      0.00      0.00       187\n        Rock       0.54      0.90      0.68      7168\n\n    accuracy                           0.57     16036\n   macro avg       0.52      0.25      0.28     16036\nweighted avg       0.57      0.57      0.51     16036\n\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "classifers = [RandomForestClassifier(), MultinomialNB(), LogisticRegression()]\n",
    "train_predict(classifers)"
   ]
  }
 ]
}