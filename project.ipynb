{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project\n",
    "# github restricts file size, dataset can be downloaded from https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-ba8f74671894>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-ba8f74671894>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ** Anthing you like **\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<h1 align = \"center\">Genre Classification by Lyric Analysis</h1>\n",
    "<h2 align = \"center\">Dataming Project</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Introduction</h2>\n",
    "<p>\n",
    "Online streaming platforms like Apple Music and Spotify add new songs to their collection daily. Each platform gives users the ability to listen to and download millions unque of songs. These songs are catalogued and categorized so that music listeners may find new songs that match their unique tastes. \n",
    "\n",
    "Organizing songs by genre is an old and familiar technique to categorize music and make it easier for listeners to find songs they like. To classify songs into genres manually, someone would need to listen to it and select the genre that best applies. This is hard and very time-consuming job. They would require a knowledge of ,many different genres, types of music and the nuances between them. \n",
    "\n",
    "Machine learning and text lyric analysis can aid in this pursuit. \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "This report serves to identify if there is a link between word frequency within the lyrics of a song and genre that the song belongs to. By using different machine learning techniques and word frequency analysis ....\n",
    "\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-6f0fcee9419e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-6f0fcee9419e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <h2>The Dataset</h2>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<h2>The Dataset</h2>\n",
    "<p>The dataset can be obtained</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "\n",
    "# remove all the genres with not avaliable and other\n",
    "data = data[data.genre != 'Not Available']\n",
    "data = data[data.genre != 'Other']\n",
    "\n",
    "# remove all the data with no lyrics\n",
    "data.dropna(subset=['lyrics'], inplace=True)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "import matplotlib\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('lyrics.csv')\n",
    "data.head()\n",
    "\n",
    "# temp so that it runs during testing\n",
    "data = data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "AxesSubplot(0.125,0.125;0.775x0.755)\n"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data['genre'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>10</th>\n      <th>24</th>\n      <th>2x</th>\n      <th>40</th>\n      <th>4x</th>\n      <th>absent</th>\n      <th>achtung</th>\n      <th>across</th>\n      <th>act</th>\n      <th>acted</th>\n      <th>...</th>\n      <th>za</th>\n      <th>zaman</th>\n      <th>zlar</th>\n      <th>zlä</th>\n      <th>zu</th>\n      <th>zum</th>\n      <th>zä</th>\n      <th>ã¼ndã¼m</th>\n      <th>ã¼nkã¼</th>\n      <th>ã¼ã</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 1500 columns</p>\n</div>",
      "text/plain": "     10  24  2x  40  4x  absent  achtung  across  act  acted  ...  za  zaman  \\\n0     0   0   0   0   0       0        0       0    0      0  ...   0      0   \n1     0   0   0   0   0       0        0       0    0      1  ...   0      0   \n2     0   0   0   0   0       0        0       0    0      0  ...   0      0   \n3     0   0   0   0   0       0        0       0    0      0  ...   0      0   \n4     0   0   0   0   0       0        0       0    0      0  ...   0      0   \n..   ..  ..  ..  ..  ..     ...      ...     ...  ...    ...  ...  ..    ...   \n995   0   0   0   0   0       0        0       0    0      0  ...   0      0   \n996   0   0   0   0   0       0        0       0    0      0  ...   0      0   \n997   0   0   0   0   0       0        0       0    0      0  ...   0      0   \n998   0   0   0   0   0       0        0       0    0      0  ...   0      0   \n999   0   0   0   0   0       0        0       0    0      0  ...   0      0   \n\n     zlar  zlä  zu  zum  zä  ã¼ndã¼m  ã¼nkã¼  ã¼ã  \n0       0    0   0    0   0        0       0    0  \n1       0    0   0    0   0        0       0    0  \n2       0    0   0    0   0        0       0    0  \n3       0    0   0    0   0        0       0    0  \n4       0    0   0    0   0        0       0    0  \n..    ...  ...  ..  ...  ..      ...     ...  ...  \n995     0    0   0    0   0        0       0    0  \n996     0    0   0    0   0        0       0    0  \n997     0    0   0    0   0        0       0    0  \n998     0    0   0    0   0        0       0    0  \n999     0    0   0    0   0        0       0    0  \n\n[1000 rows x 1500 columns]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# max_features : a maximum of 1500 columns\n",
    "# min_df : the word must occur in a mininum of 5 documents\n",
    "# max_df : the word occurs in less than 70 percent of the documents (words appearing in all are useless)\n",
    "# nltk.download('stopwords')\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=2, max_df=0.7, stop_words=stopwords.words('english'), token_pattern = '[a-zA-Z]+')\n",
    "\n",
    "# creates a bag of words\n",
    "X = vectorizer.fit_transform(data.lyrics.values.astype('str'))\n",
    "\n",
    "# creates y, which is our genre class\n",
    "y = data.genre\n",
    "\n",
    "# visualize the transformed data \n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    ",# find the TFID reference: http://www.tfidf.com/\n",
    "# mitigates the fact that the word may have a high frequency in other documents\n",
    "\n",
    "# TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "# IDF(t) = log_e(Total number of documents / Number of documents with term t in it). <-- appro \n",
    "    # if all documents have the term in it then it has a score of 0 TF * log(1) = 0\n",
    "    # it will weigh rare words heigher \n",
    "\n",
    "# TFIDF = TF * IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>10</th>\n      <th>24</th>\n      <th>2x</th>\n      <th>40</th>\n      <th>4x</th>\n      <th>absent</th>\n      <th>achtung</th>\n      <th>across</th>\n      <th>act</th>\n      <th>acted</th>\n      <th>...</th>\n      <th>za</th>\n      <th>zaman</th>\n      <th>zlar</th>\n      <th>zlä</th>\n      <th>zu</th>\n      <th>zum</th>\n      <th>zä</th>\n      <th>ã¼ndã¼m</th>\n      <th>ã¼nkã¼</th>\n      <th>ã¼ã</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.109817</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 1500 columns</p>\n</div>",
      "text/plain": "      10   24   2x   40   4x  absent  achtung  across  act     acted  ...  \\\n0    0.0  0.0  0.0  0.0  0.0     0.0      0.0     0.0  0.0  0.000000  ...   \n1    0.0  0.0  0.0  0.0  0.0     0.0      0.0     0.0  0.0  0.109817  ...   \n2    0.0  0.0  0.0  0.0  0.0     0.0      0.0     0.0  0.0  0.000000  ...   \n3    0.0  0.0  0.0  0.0  0.0     0.0      0.0     0.0  0.0  0.000000  ...   \n4    0.0  0.0  0.0  0.0  0.0     0.0      0.0     0.0  0.0  0.000000  ...   \n..   ...  ...  ...  ...  ...     ...      ...     ...  ...       ...  ...   \n995  0.0  0.0  0.0  0.0  0.0     0.0      0.0     0.0  0.0  0.000000  ...   \n996  0.0  0.0  0.0  0.0  0.0     0.0      0.0     0.0  0.0  0.000000  ...   \n997  0.0  0.0  0.0  0.0  0.0     0.0      0.0     0.0  0.0  0.000000  ...   \n998  0.0  0.0  0.0  0.0  0.0     0.0      0.0     0.0  0.0  0.000000  ...   \n999  0.0  0.0  0.0  0.0  0.0     0.0      0.0     0.0  0.0  0.000000  ...   \n\n      za  zaman  zlar  zlä   zu  zum   zä  ã¼ndã¼m  ã¼nkã¼  ã¼ã  \n0    0.0    0.0   0.0  0.0  0.0  0.0  0.0      0.0     0.0  0.0  \n1    0.0    0.0   0.0  0.0  0.0  0.0  0.0      0.0     0.0  0.0  \n2    0.0    0.0   0.0  0.0  0.0  0.0  0.0      0.0     0.0  0.0  \n3    0.0    0.0   0.0  0.0  0.0  0.0  0.0      0.0     0.0  0.0  \n4    0.0    0.0   0.0  0.0  0.0  0.0  0.0      0.0     0.0  0.0  \n..   ...    ...   ...  ...  ...  ...  ...      ...     ...  ...  \n995  0.0    0.0   0.0  0.0  0.0  0.0  0.0      0.0     0.0  0.0  \n996  0.0    0.0   0.0  0.0  0.0  0.0  0.0      0.0     0.0  0.0  \n997  0.0    0.0   0.0  0.0  0.0  0.0  0.0      0.0     0.0  0.0  \n998  0.0    0.0   0.0  0.0  0.0  0.0  0.0      0.0     0.0  0.0  \n999  0.0    0.0   0.0  0.0  0.0  0.0  0.0      0.0     0.0  0.0  \n\n[1000 rows x 1500 columns]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice how the data is now altered based on the word frequency\n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training a test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_predict(classifiers):\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        print(classifier.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\nRandomForestClassifier 0.616\n               precision    recall  f1-score   support\n\n      Country       0.00      0.00      0.00        13\n   Electronic       0.00      0.00      0.00         4\n      Hip-Hop       0.94      0.74      0.83        23\n         Jazz       0.00      0.00      0.00         9\n        Metal       0.20      1.00      0.33         2\nNot Available       1.00      0.36      0.53        14\n        Other       0.84      0.61      0.70        51\n          Pop       0.70      0.84      0.76        76\n         Rock       0.40      0.60      0.48        58\n\n     accuracy                           0.62       250\n    macro avg       0.45      0.46      0.40       250\n weighted avg       0.62      0.62      0.60       250\n\nMultinomialNB 0.584\n               precision    recall  f1-score   support\n\n      Country       0.00      0.00      0.00        13\n   Electronic       0.00      0.00      0.00         4\n      Hip-Hop       0.85      0.74      0.79        23\n         Jazz       0.00      0.00      0.00         9\n        Metal       0.00      0.00      0.00         2\nNot Available       1.00      0.07      0.13        14\n        Other       1.00      0.55      0.71        51\n          Pop       0.54      0.87      0.67        76\n         Rock       0.43      0.59      0.50        58\n\n     accuracy                           0.58       250\n    macro avg       0.42      0.31      0.31       250\n weighted avg       0.60      0.58      0.54       250\n\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\nLogisticRegression 0.632\n               precision    recall  f1-score   support\n\n      Country       0.00      0.00      0.00        13\n   Electronic       0.00      0.00      0.00         4\n      Hip-Hop       0.85      0.74      0.79        23\n         Jazz       0.00      0.00      0.00         9\n        Metal       0.00      0.00      0.00         2\nNot Available       0.00      0.00      0.00        14\n        Other       0.90      0.73      0.80        51\n          Pop       0.63      0.84      0.72        76\n         Rock       0.46      0.69      0.55        58\n\n     accuracy                           0.63       250\n    macro avg       0.32      0.33      0.32       250\n weighted avg       0.56      0.63      0.58       250\n\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "classifers = [RandomForestClassifier(), MultinomialNB(), LogisticRegression()]\n",
    "train_predict(classifers)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
