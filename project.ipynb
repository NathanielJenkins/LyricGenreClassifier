{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\">Genre Classification by Lyric Analysis</h1>\n",
    "<h2 align = \"center\">Data mining Project</h2>\n",
    "<h4 align = \"center\">\n",
    "    \n",
    "    Nathan Jenkins\n",
    "    Vincent Potrykus\n",
    "    Jordan Sandberg\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>\n",
    "<p>\n",
    "Online streaming platforms like Apple Music and Spotify add new songs to their collection daily. Each platform gives users the ability to listen to and download millions unique of songs. These songs are catalogued and categorized so that music listeners may find new songs that match their unique tastes. \n",
    "\n",
    "Organizing songs by genre is an old and familiar technique to categorize music and make it easier for listeners to find songs they like. To classify songs into genres manually, someone would need to listen to it and select the genre that best applies. This is hard and very time-consuming job. They would require a knowledge of ,many different genres, types of music and the nuances between them. \n",
    "\n",
    "Machine learning and text lyric analysis can aid in this pursuit. \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "This report serves to identify if there is a link between word frequency within the lyrics of a song and genre that the song belongs to. The notebook will analyses the effectiveness of different machine learning techniques, algorithms and natural language processing tools to determine the correlation between lyrics and musical genres. \n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The Dataset</h2>\n",
    "<p>The dataset can be obtained from kaggle at the following <a href = \"https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics/data\">link. </p>\n",
    "<p><font color = red>\n",
    "<strong>IMPORTANT: Place the <i>lyrics.csv</i> file in the same folder as the <i>project.ipynb</i> file (thisfile)</strong></font></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people, the people the party it's po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  song  year           artist genre  \\\n",
       "index                                                 \n",
       "0            ego-remix  2009  beyonce-knowles   Pop   \n",
       "1         then-tell-me  2009  beyonce-knowles   Pop   \n",
       "2              honesty  2009  beyonce-knowles   Pop   \n",
       "3      you-are-my-rock  2009  beyonce-knowles   Pop   \n",
       "4        black-culture  2009  beyonce-knowles   Pop   \n",
       "\n",
       "                                                  lyrics  \n",
       "index                                                     \n",
       "0      Oh baby, how you doing?\\nYou know I'm gonna cu...  \n",
       "1      playin' everything so easy,\\nit's like you see...  \n",
       "2      If you search\\nFor tenderness\\nIt isn't hard t...  \n",
       "3      Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...  \n",
       "4      Party the people, the people the party it's po...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('lyrics.csv', index_col=0)\n",
    "\n",
    "# show the format of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This dataset contains 380,000 rows in the format <i>song/year/artist/genre/lyrics</i>/</p>\n",
    "<p>Each song ranges from a number of genres, including: <b>Rock, Pop, Hip-Hop, Metal, Country, Jazz, Electronic, Indie, R&B, and Folk</b> For the context of this project, the columns of interest are <i>lyrics</i> the attributes, and <i>genre,</i> the target class. Where the lyrics will first need to be vectorized, where each word is a token and the frequency of occurrence related to their importance of classifying the song.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "\n",
    "# remove all the genres with not avaliable and other\n",
    "data = data[data.genre != 'Not Available']\n",
    "data = data[data.genre != 'Other']\n",
    "data = data[data.genre != 'Folk']\n",
    "\n",
    "# remove all the data with no lyrics\n",
    "data.dropna(subset=['lyrics'], inplace=True)\n",
    "\n",
    "# sample a smaller subset of data since it is quite large for processing\n",
    "data = data.sample(n=10000, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preprocessing</h2>\n",
    "<h3>Removing unnecessary data</h3>\n",
    "\n",
    "<p>The first step of the process is preprocessing the data so that we can use it in the algorithm. First, we remove all rows of non-importance from the collection, that is, rows where the genre is \"Not Available\" or \"Other\". Second, we delete all the rows that do not contain lyrics. In the next step, Count Vectorizer, we remove all \"non-words\", that is emojis and all tokens that are not composed solely of the letters of the alphabet, and \"stop words\", that is common words that are unlikely to be specific to a document, such as \"and\", \"the\", \"a\", etc.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>afraid</th>\n",
       "      <th>age</th>\n",
       "      <th>ago</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahead</th>\n",
       "      <th>ai</th>\n",
       "      <th>aint</th>\n",
       "      <th>air</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>youth</th>\n",
       "      <th>yuh</th>\n",
       "      <th>z</th>\n",
       "      <th>zu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   across  act  afraid  age  ago  ah  ahead  ai  aint  air  ...  yesterday  \\\n",
       "0       0    0       0    0    0   0      0   0     0    0  ...          0   \n",
       "1       0    0       0    0    0   0      0   0     0    0  ...          0   \n",
       "2       0    0       0    0    0   0      0   0     0    0  ...          0   \n",
       "3       0    0       0    0    0   0      0   0     0    0  ...          0   \n",
       "4       0    0       0    0    0   0      0   0     0    0  ...          0   \n",
       "\n",
       "   yet  yo  york  young  youre  youth  yuh  z  zu  \n",
       "0    1   0     0      0      0      0    0  0   0  \n",
       "1    0   0     0      0      0      0    0  0   0  \n",
       "2    0   0     0      0      0      0    0  0   0  \n",
       "3    0   0     0      0      0      0    0  0   0  \n",
       "4    0   0     0      0      0      0    0  0   0  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# max_features : a maximum of 1500 columns\n",
    "# min_df : the word must occur in a mininum of 5 documents\n",
    "# max_df : the word occurs in less than 70 percent of the documents (words appearing in all are useless)\n",
    "# nltk.download('stopwords')\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'), token_pattern = '[a-zA-Z]+')\n",
    "\n",
    "# creates a bag of words\n",
    "X = vectorizer.fit_transform(data.lyrics.values.astype('str'))\n",
    "\n",
    "# creates y, which is our genre class\n",
    "y = data.genre\n",
    "\n",
    "# visualize the transformed data \n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Count Vectorizer</h3>\n",
    "\n",
    "This step converts the initial document to a vector of tokens. Where each token is the amount of times the word appears in the document.\n",
    "<h4>Important metrics to consider</h4>\n",
    "\n",
    "1. Max features: The maximum number of words to consider as attributes\n",
    "2. min_df : The minimum number of documents the word must appear in to be considered.\n",
    "       - if a word appears in very few song lyrics then this word has little affect on determining the class\n",
    "3. max_df : The word appears in a maximum of this many documents. \n",
    "       - if a word appears in too many documents then it has no affect on determine the class\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>afraid</th>\n",
       "      <th>age</th>\n",
       "      <th>ago</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahead</th>\n",
       "      <th>ai</th>\n",
       "      <th>aint</th>\n",
       "      <th>air</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>youth</th>\n",
       "      <th>yuh</th>\n",
       "      <th>z</th>\n",
       "      <th>zu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   across  act  afraid  age  ago   ah  ahead   ai  aint  air  ...  yesterday  \\\n",
       "0     0.0  0.0     0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  ...        0.0   \n",
       "1     0.0  0.0     0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  ...        0.0   \n",
       "2     0.0  0.0     0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  ...        0.0   \n",
       "3     0.0  0.0     0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  ...        0.0   \n",
       "4     0.0  0.0     0.0  0.0  0.0  0.0    0.0  0.0   0.0  0.0  ...        0.0   \n",
       "\n",
       "        yet   yo  york  young  youre  youth  yuh    z   zu  \n",
       "0  0.052699  0.0   0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "1  0.000000  0.0   0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "2  0.000000  0.0   0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "3  0.000000  0.0   0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "4  0.000000  0.0   0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)\n",
    "\n",
    "# notice how the data is now altered based on the word frequency\n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TF-IDF Vectorizer</h3>\n",
    "<p><a href = \"http://www.tfidf.com\"> \"Term frequency inverse document\"</a>is a more sophisticated method of vectorization. Each word is assigned a weight from 0 to 1 that is a measure of the words importance to collection of documents. That is, this metric is proportional to the amount of times the word appears in the document, offset by the amount of times the word appears in the entirety of the collection</p>\n",
    "<p>The metric TFIDF is calculated by: $TFIDF = TF * IDF$\n",
    "</p>\n",
    "\n",
    "$$TF(t) = \\frac{\\text{number of times term t appears in the document}}{\\text {total number of terms in the document}}$$\n",
    "\n",
    "$$IDF(t) = \\ln{\\left( \\frac{\\text{Total number of documents}}{\\text{Number of documents with term t}}\\right) }$$\n",
    "\n",
    "<p>If all the document contains the term t, this term will have a score of 0. Since $TF * ln(1) = 0$</p>\n",
    "<p>If the term t is rare, then IDF will be larger. Then TF-IDF will be larger</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1149f0610>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imbalanced Data</h3>\n",
    "<p>This graph shows us that the dataset has some very imbalanced data. There is a disproportionate amount of rock songs than others. With this dataset, if an algorithm guessed rock 100% of the time, it would achieve around 50% accuracy for this class. </p>\n",
    "\n",
    "<p>To address the issue of imbalanced data, we are going to oversample the data from the under represented classes.</p>\n",
    "\n",
    "<p><code>imblearn.oversampling.RandomOverSampler</code> does this by picking random samples with replacement</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training a test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Split the data into training and testing using <code>train_test_splot</code> from <code>sklearn</code></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11b030390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "X_train_oversampled, y_train_oversampled = RandomOverSampler().fit_resample(X_train, y_train)\n",
    "pd.DataFrame(y_train_oversampled)[0].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>By employing the sampling techniques, each class now has an equivalent amount of rows that can be used to train the algorithms. It is important that these rows are only used for training, and the algorithms are evaluated on the unbiased data, since the unbiased data is more representational of the population, and real world analyses.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Experiment and Analysis</h2>\n",
    "<p>The following algorithms will be evaluated to in their ability to classify the data</p>\n",
    "1. Random Forest Classifier\n",
    "2. Multinomial Bayes\n",
    "3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "\n",
    "classifers = [RandomForestClassifier(), MultinomialNB(), LogisticRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "def train_predict(classifiers, X_train=X_train, y_train=y_train):\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        print(classifier.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Lets first compare how successful training with the unbiased vs the sampled bias data is with multinomial bayes to see if sampling the data made a difference</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB 0.29576841962038236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.22      0.57      0.32      3626\n",
      "  Electronic       0.09      0.22      0.13      1972\n",
      "     Hip-Hop       0.61      0.71      0.65      6271\n",
      "       Indie       0.04      0.34      0.07       785\n",
      "        Jazz       0.19      0.36      0.25      1940\n",
      "       Metal       0.44      0.67      0.53      5973\n",
      "         Pop       0.39      0.17      0.24     10068\n",
      "         R&B       0.04      0.42      0.07       829\n",
      "        Rock       0.71      0.13      0.21     27332\n",
      "\n",
      "    accuracy                           0.30     58796\n",
      "   macro avg       0.30      0.40      0.28     58796\n",
      "weighted avg       0.53      0.30      0.30     58796\n",
      "\n",
      "MultinomialNB 0.5592727396421525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.73      0.00      0.01      3626\n",
      "  Electronic       0.13      0.00      0.00      1972\n",
      "     Hip-Hop       0.79      0.65      0.71      6271\n",
      "       Indie       0.00      0.00      0.00       785\n",
      "        Jazz       0.50      0.00      0.00      1940\n",
      "       Metal       0.73      0.36      0.48      5973\n",
      "         Pop       0.42      0.14      0.21     10068\n",
      "         R&B       0.00      0.00      0.00       829\n",
      "        Rock       0.53      0.92      0.68     27332\n",
      "\n",
      "    accuracy                           0.56     58796\n",
      "   macro avg       0.43      0.23      0.23     58796\n",
      "weighted avg       0.54      0.56      0.48     58796\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_predict([MultinomialNB()], X_train = X_train_oversampled, y_train = y_train_oversampled)\n",
    "train_predict([MultinomialNB()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "mining",
   "language": "python",
   "name": "build_central"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
