{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project\n",
    "# github restricts file size, dataset can be downloaded from https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\">Genre Classification by Lyric Analysis</h1>\n",
    "<h2 align = \"center\">Data Mining Project</h2>\n",
    "<h4 align = \"center\">\n",
    "Nathan Jenkins<br>\n",
    "Vincent Potrykus<br>\n",
    "Jordan Sandberg<br>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>\n",
    "<p>\n",
    "Online streaming platforms like Apple Music and Spotify add new songs to their collection daily. Each platform gives users the ability to listen to and download millions unque of songs. These songs are catalogued and categorized so that music listeners may find new songs that match their unique tastes. \n",
    "\n",
    "Organizing songs by genre is an old and familiar technique to categorize music and make it easier for listeners to find songs they like. To classify songs into genres manually, someone would need to listen to it and select the genre that best applies. This is hard and very time-consuming job. They would require a knowledge of many different genres, types of music and the nuances between them. \n",
    "\n",
    "Machine learning and text lyric analysis can aid in this pursuit. \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "This report serves to identify if there is a link between word frequency within the lyrics of a song and genre that the song belongs to. By using different machine learning techniques and word frequency analysis ....\n",
    "</p>\n",
    "\n",
    "<h2>The Dataset</h2>\n",
    "<p>\n",
    "    The dataset can be obtained at: \n",
    "    <a href=https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics/data>\n",
    "        https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics/data\n",
    "    </a>\n",
    "    <br>\n",
    "    <font color = \"red\">\n",
    "        <strong>IMPORTANT: Place the <i>lyrics.csv</i> file in the same folder \n",
    "            as the <i>project.ipynb</i> file (this file).</strong>\n",
    "    </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preprocessing</h2>\n",
    "<h3>Removing unnecessary data</h3>\n",
    "<p>\n",
    "    The first step of the process is preprocessing the data so that we can use it in the algorithm. First, we delete all invalid rows from the database, that is, rows where the genre is \"Not Available\" or \"Other\". Second, we delete all the rows that do not contain lyrics. In the next step, Count Vectorizer, we remove all \"non-words\", that is emojis and all tokens that arent composed solely of the letters of the alphabet, and \"stop words\", that is common words that are unlikely to be specific to a document, such as \"and\", \"the\", \"a\", etc.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('lyrics.csv')\n",
    "data.head()\n",
    "\n",
    "# temp so that it runs during testing\n",
    "data = data[:10000]\n",
    "\n",
    "# preprocess the data\n",
    "\n",
    "# remove all the genres with not avaliable and other\n",
    "data = data[data.genre != 'Not Available']\n",
    "data = data[data.genre != 'Other']\n",
    "\n",
    "\n",
    "# remove all the data with no lyrics\n",
    "data.dropna(subset=['lyrics'], inplace=True)\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people, the people the party it's po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             song  year           artist genre  \\\n",
       "0      0        ego-remix  2009  beyonce-knowles   Pop   \n",
       "1      1     then-tell-me  2009  beyonce-knowles   Pop   \n",
       "2      2          honesty  2009  beyonce-knowles   Pop   \n",
       "3      3  you-are-my-rock  2009  beyonce-knowles   Pop   \n",
       "4      4    black-culture  2009  beyonce-knowles   Pop   \n",
       "\n",
       "                                              lyrics  \n",
       "0  Oh baby, how you doing?\\nYou know I'm gonna cu...  \n",
       "1  playin' everything so easy,\\nit's like you see...  \n",
       "2  If you search\\nFor tenderness\\nIt isn't hard t...  \n",
       "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...  \n",
       "4  Party the people, the people the party it's po...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Count Vectorizer</h3>\n",
    "<p>\n",
    "    This steps converts the initial database to a matrix of token counts. Here we also remove all \"stop words\" and \"non-words\".\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>admit</th>\n",
       "      <th>afraid</th>\n",
       "      <th>age</th>\n",
       "      <th>ago</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahead</th>\n",
       "      <th>aim</th>\n",
       "      <th>aint</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yippie</th>\n",
       "      <th>yo</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>youth</th>\n",
       "      <th>yuh</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6212 rows Ã— 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      across  act  admit  afraid  age  ago  ah  ahead  aim  aint  ...  \\\n",
       "0          0    0      1       0    0    0   0      0    0     0  ...   \n",
       "1          0    0      0       0    0    0   0      0    0     0  ...   \n",
       "2          0    0      0       0    0    0   0      0    0     0  ...   \n",
       "3          0    0      0       0    0    0   0      0    0     0  ...   \n",
       "4          0    0      0       0    0    0   0      0    0     0  ...   \n",
       "...      ...  ...    ...     ...  ...  ...  ..    ...  ...   ...  ...   \n",
       "6207       0    0      0       0    0    0   0      0    6     0  ...   \n",
       "6208       0    0      0       0    0    0   0      0    0     0  ...   \n",
       "6209       0    0      0       0    0    0   0      0    0     0  ...   \n",
       "6210       0    0      0       0    0    0   0      0    0     0  ...   \n",
       "6211       0    0      0       0    0    0   0      0    0     0  ...   \n",
       "\n",
       "      yesterday  yet  yippie  yo  york  young  youre  youth  yuh  z  \n",
       "0             0    1       0   0     0      0      0      0    0  0  \n",
       "1             0    0       0   0     0      0      0      0    0  0  \n",
       "2             0    0       0   0     0      0      0      0    0  0  \n",
       "3             0    0       0   0     0      0      0      0    0  0  \n",
       "4             0    0       0   0     0      0      0      0    0  0  \n",
       "...         ...  ...     ...  ..   ...    ...    ...    ...  ... ..  \n",
       "6207          0    0       0   0     0      0      0      0    0  0  \n",
       "6208          0    0       0   0     0      0      0      0    0  0  \n",
       "6209          0    0       0   0     0      0      0      0    0  0  \n",
       "6210          0    0       0   0     0      0      0      0    0  0  \n",
       "6211          0    0       0   0     0      0      0      0    0  0  \n",
       "\n",
       "[6212 rows x 1500 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# max_features : a maximum of 1500 columns\n",
    "# min_df : the word must occur in a mininum of 5 documents\n",
    "# max_df : the word occurs in less than 70 percent of the documents (words appearing in all are useless)\n",
    "# nltk.download('stopwords')\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=2, max_df=0.7, stop_words=stopwords.words('english'), token_pattern = '[a-zA-Z]+')\n",
    "\n",
    "# creates a bag of words\n",
    "X = vectorizer.fit_transform(data.lyrics.values.astype('str'))\n",
    "\n",
    "# creates y, which is our genre class\n",
    "y = data.genre\n",
    "\n",
    "# visualize the transformed data \n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    ",# find the TFID reference: http://www.tfidf.com/\n",
    "# mitigates the fact that the word may have a high frequency in other documents\n",
    "\n",
    "# TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "# IDF(t) = log_e(Total number of documents / Number of documents with term t in it). <-- appro \n",
    "    # if all documents have the term in it then it has a score of 0 TF * log(1) = 0\n",
    "    # it will weigh rare words heigher \n",
    "\n",
    "# TFIDF = TF * IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice how the data is now altered based on the word frequency\n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training a test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_predict(classifiers):\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        print(classifier.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "RandomForestClassifier 0.5692816163631829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.49      0.19      0.28      1156\n",
      "  Electronic       0.55      0.09      0.15       535\n",
      "        Folk       0.77      0.18      0.29       204\n",
      "     Hip-Hop       0.81      0.74      0.77      1606\n",
      "       Indie       0.69      0.05      0.09       193\n",
      "        Jazz       0.61      0.21      0.31       563\n",
      "       Metal       0.58      0.34      0.43      1617\n",
      "         Pop       0.46      0.31      0.37      2807\n",
      "         R&B       0.75      0.10      0.17       187\n",
      "        Rock       0.56      0.85      0.67      7168\n",
      "\n",
      "    accuracy                           0.57     16036\n",
      "   macro avg       0.63      0.31      0.35     16036\n",
      "weighted avg       0.57      0.57      0.53     16036\n",
      "\n",
      "MultinomialNB 0.5277500623596907\n",
      "/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.63      0.01      0.03      1156\n",
      "  Electronic       0.86      0.03      0.06       535\n",
      "        Folk       0.89      0.04      0.08       204\n",
      "     Hip-Hop       0.77      0.65      0.70      1606\n",
      "       Indie       0.00      0.00      0.00       193\n",
      "        Jazz       1.00      0.00      0.00       563\n",
      "       Metal       0.71      0.27      0.39      1617\n",
      "         Pop       0.37      0.11      0.18      2807\n",
      "         R&B       0.00      0.00      0.00       187\n",
      "        Rock       0.50      0.92      0.65      7168\n",
      "\n",
      "    accuracy                           0.53     16036\n",
      "   macro avg       0.57      0.20      0.21     16036\n",
      "weighted avg       0.56      0.53      0.44     16036\n",
      "\n",
      "/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nathanjenkins/opt/anaconda3/envs/mining/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "LogisticRegression 0.5675355450236966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.59      0.20      0.30      1156\n",
      "  Electronic       0.81      0.04      0.07       535\n",
      "        Folk       0.83      0.07      0.14       204\n",
      "     Hip-Hop       0.85      0.67      0.75      1606\n",
      "       Indie       0.00      0.00      0.00       193\n",
      "        Jazz       0.42      0.04      0.08       563\n",
      "       Metal       0.68      0.36      0.47      1617\n",
      "         Pop       0.47      0.24      0.32      2807\n",
      "         R&B       0.00      0.00      0.00       187\n",
      "        Rock       0.54      0.90      0.68      7168\n",
      "\n",
      "    accuracy                           0.57     16036\n",
      "   macro avg       0.52      0.25      0.28     16036\n",
      "weighted avg       0.57      0.57      0.51     16036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "classifers = [RandomForestClassifier(), MultinomialNB(), LogisticRegression()]\n",
    "train_predict(classifers)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
